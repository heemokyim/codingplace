* Hadoop stack

HDFS
	1. 여러 클러스터를 하나의 FS로 처리
	2. resilience를 위해 copy를 뜸

YARN
	1. 클러스터 resource를 관리함.
	2. 어떤 executor가 어떤 task를 하고 어떤 resource를 줘야 되고 언제 해야 되는지 etc

MAPREDUCE
	1. 프로그래밍 방법론임 Map 후 Reduce
	2. 방법론 아닐 수도 있고 소프트웨어프레임워크일수도..

Pig
	1. 프로그래밍 언어 없이 SQL 비스무리한 애들로 다양한 쿼리를 날리는 high level API
	2. SQL 비스무리한 애들을 주면 알아서 script로 바꿔서 yarn이나 HDFS에 날림

Hive
	1. pig랑 비슷한데 SQL database처럼 작동하는 애임
	2. Hadoop cluster에 있는 data를 하나의 db로 모아주는 애인듯. 얘에다가 쿼리날리면 마치 하나의 DB에 쿼리날리듯이 동작하게 하는 애

Ambari
	1. 모든 HDFS에 대한 Web UI

MESOS
	1. Yarn과 비슷한데 장점 단점이 조금씩 다름

Spark
	1. MapReduce 기반 script함수를 제공해서 고성능 분산처리를 지원하는 프레임워크
	2. Reliable, Distributed
	3. 최적화를 위한 DataFrame, Spark자체적으로 테이블을 만들고 SQL을 날림
	4. MLLib를 이용해서 트레이닝을 빨리 시킴
	Spark streaming, GraphX, MLLib, Spark SQL

TEZ
	1. MapReduce단에 있고 동작방식은 Spark와 비슷함. DAG를 사용
	2. SQL 최적화되있고 보통 Hive랑 같이 쓴다 (두 놈 다 SQL Query에 최적화된 놈인듯)
	3. TEZ와 Hive는 같이 쓰면 좋댄다 (Pig도 같이 잘 섞어쓰는듯)

HBASE
	1. NoSQL Database
	2. 정말정말 큰 데이터 + 빠른 트렌젝션을 지원하기 위해 씀
	3. 예를 들어 사람이 많이 들어오는 웹페이지에서 쓰임
	4. expose the data that's stored on cluster
	5. 빨라서 다른 system(스파크나 Mapreduce framework)에 전달하기 위해 사용

Apache Storm
	1. Processing streaming data, (Sensor data, web logs) 스파크 스트리밍이랑 비슷함
	2. 머신러닝 모델을 update, or 데이터를 실시간으로 DB에 저장하는 등

----------------------------------------------------------------------------------------------------

* Integrator

Oozie
	1. Job scheduler for HDFS
	2. 각기 다른 시스템으로부터 job들을 처리해야 하는 경우, 스케쥴 형태로 처리하게 도와줌
	3. 예를 들어 Hive에서 데이터 가져오고 pig로 합치고 Spark로 처리하고 HBase로 넣어야 하는 경우

Zookeeper
	1. HDFS의 모든 componenet들을 추적하는 용도로 쓰임 (얘가 꺼졌나 켜졌나)
	2. Hadoop cluster의 resilience, consistency를 위해 작동한다
	3. Master node는 뭐고 executor node는 뭔지

----------------------------------------------------------------------------------------------------

* Data Ingestion (streaming)

SQOOP
	1. Connector between Hadoop and legacy DB (원래 쓰던 DB를 HDFS로 옮겨주는 놈)

Flume
	1. 대용량 웹로그를 streaming으로 처리하는데 특화된 놈

Kafka
	1. Flume보다 더 일반적인 목적으로 사용됨 (웹로그말고 다른 데이터도 대용량으로 처리하는데 streaming 처리하는데 특화됬다)


----------------------------------------------------------------------------------------------------

* External Data Storage

MySQL, cassandra, mongoDB


----------------------------------------------------------------------------------------------------

* Query engines
(Hive는 Hadoop이랑 밀접하게 연관되서 이 파트에선 뺌)

Apache Drill
	1. NoSQL DB 전부에 쿼리를 날릴 수 있는 애임

Hue
	1. Interactive query, visualize를 담당

Apache Phonix
	1. SQL지원, OLTP에 ACID를 보장
	2. SQL이 아닌 DB도 RDB인 것처럼 다룸

presto
	1. 강사도 잘 모르는 듯

Zepplin
	1. Notebook UI스타일로 query


----------------------------------------------------------------------------------------------------

** Hadoop Eco System의 핵심
	=> 해결해야 할 Business Problem해결을 위해 어떤 component를 선택해서 해결할 건가

